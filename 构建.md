# 如何构建模型
### 1.环境准备
在命令行中输入以下命令：
```
# 默认安装CPU版本，安装paddle时建议使用百度源
pip install paddlepaddle -i https://mirror.baidu.com/pypi/simple
# 在命令行中输入以下命令：
pip install paddlehub -i https://mirror.baidu.com/pypi/simple
hub install realsr==1.0.1
```
### 2.服务部署
```
hub serving start -m realsr
```
这样就完成了一个图像超分的在线服务API的部署，默认端口号为8866。

NOTE: 如使用GPU预测，则需要在启动服务之前，请设置CUDA_VISIBLE_DEVICES环境变量，否则不用设置。

### 3.发送预测请求
```python
import requests
import json
import base64

import cv2
import numpy as np

def cv2_to_base64(image):
    data = cv2.imencode('.jpg', image)[1]
    return base64.b64encode(data.tostring()).decode('utf8')
def base64_to_cv2(b64str):
    data = base64.b64decode(b64str.encode('utf8'))
    data = np.fromstring(data, np.uint8)
    data = cv2.imdecode(data, cv2.IMREAD_COLOR)
    return data

# 发送HTTP请求
org_im = cv2.imread('/PATH/TO/IMAGE')
data = {'images':cv2_to_base64(org_im)}
headers = {"Content-type": "application/json"}
url = "http://127.0.0.1:8866/predict/realsr"
r = requests.post(url=url, headers=headers, data=json.dumps(data))
img = base64_to_cv2(r.json()["results"])
cv2.imwrite('/PATH/TO/SAVE/IMAGE', img)
```
😲注意测试图片尺寸不能太大，否则可能会爆内存！另外如果是在cpu推理，推理延迟较高（30s）可以测试一下GPU加速
